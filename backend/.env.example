# OmniAI Backend Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# SERVER
# =============================================================================
HOST=127.0.0.1
PORT=8000
DEBUG=false
LOG_LEVEL=INFO

# =============================================================================
# SECURITY
# =============================================================================
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
SECRET_KEY=CHANGE_ME_IN_PRODUCTION

# CORS allowed origins (comma-separated)
CORS_ORIGINS=https://omniplexity.github.io

# Rate limiting (requests per minute per IP)
RATE_LIMIT_RPM=60

# Max request body size in bytes (default 1MB)
MAX_REQUEST_BYTES=1048576

# =============================================================================
# AUTHENTICATION
# =============================================================================
# Session cookie settings
SESSION_COOKIE_NAME=omni_session
SESSION_TTL_SECONDS=604800
COOKIE_SECURE=true
COOKIE_SAMESITE=lax
COOKIE_DOMAIN=

# CSRF settings
CSRF_HEADER_NAME=X-CSRF-Token
CSRF_COOKIE_NAME=omni_csrf

# Registration settings
INVITE_REQUIRED=true

# =============================================================================
# DATABASE
# =============================================================================
# SQLite (default): sqlite:///./data/omniai.db
# PostgreSQL: postgresql://user:pass@localhost:5432/omniai
DATABASE_URL=sqlite:///./data/omniai.db

# =============================================================================
# PROVIDERS (configure as needed)
# =============================================================================
# Default provider (lmstudio, ollama, or openai_compat)
PROVIDER_DEFAULT=lmstudio

# Comma-separated list of enabled providers
PROVIDERS_ENABLED=lmstudio

# Provider timeouts and retries
PROVIDER_TIMEOUT_SECONDS=30
PROVIDER_MAX_RETRIES=1
# Server-sent events keep-alive interval (seconds; set to 0 to disable)
SSE_PING_INTERVAL_SECONDS=10

# LM Studio (OpenAI-compatible local server)
LMSTUDIO_BASE_URL=http://127.0.0.1:1234

# Ollama (local LLM server)
OLLAMA_BASE_URL=http://127.0.0.1:11434

# OpenAI-compatible endpoint (generic)
OPENAI_COMPAT_BASE_URL=
OPENAI_COMPAT_API_KEY=
